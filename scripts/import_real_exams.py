#!/usr/bin/env python3
"""
å†å¹´çœŸé¢˜PDFå¯¼å…¥è„šæœ¬ - è€ƒç ”æ•°å­¦å­¦ä¹ åŠ©æ‰‹
ç”¨äºä»PDFæ–‡ä»¶ä¸­æå–å’Œè§£æå†å¹´çœŸé¢˜æ•°æ®

Phase 19: å†å¹´çœŸé¢˜æ•°æ®å½•å…¥ - è‡ªåŠ¨å¯¼å…¥å·¥å…·
"""

import os
import re
import json
import csv
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import fitz  # PyMuPDF for PDF text extraction
import pytesseract
from PIL import Image
import io


@dataclass
class QuestionCandidate:
    """é¢˜ç›®å€™é€‰å¯¹è±¡"""
    id: str
    type: str  # 'choice', 'blank', 'solve'
    content: str
    options: Optional[List[str]] = None
    answer: Optional[str] = None
    accepted_answers: Optional[List[str]] = None
    score: Optional[int] = None
    solution: Optional[str] = None
    explanation: str = ""
    knowledge_points: List[str] = None
    page_num: int = 0
    confidence: float = 0.0
    parsing_notes: str = ""


class PDFTextExtractor:
    """PDFæ–‡æœ¬æå–å™¨"""

    def __init__(self):
        self.ocr_fallback = True

    def extract_text(self, pdf_path: str) -> List[Tuple[int, str]]:
        """ä»PDFæå–æ–‡æœ¬ï¼ŒæŒ‰é¡µè¿”å›"""
        pages_text = []

        try:
            doc = fitz.open(pdf_path)

            for page_num in range(len(doc)):
                page = doc.load_page(page_num)

                # ç›´æ¥æå–æ–‡æœ¬
                text = page.get_text()

                # å¦‚æœæ–‡æœ¬å¤ªå°‘ï¼Œå°è¯•OCRï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if len(text.strip()) < 100 and self.ocr_fallback:
                    try:
                        ocr_text = self._extract_with_ocr(page)
                        if ocr_text:
                            text = ocr_text
                    except Exception as ocr_error:
                        print(f"OCR failed for page {page_num + 1}, using original text: {ocr_error}")

                pages_text.append((page_num + 1, text.strip()))

            doc.close()

        except Exception as e:
            print(f"Error extracting text from {pdf_path}: {e}")
            return []

        return pages_text

    def _extract_with_ocr(self, page) -> str:
        """ä½¿ç”¨OCRæå–æ–‡æœ¬"""
        try:
            # æ£€æŸ¥tesseractæ˜¯å¦å¯ç”¨
            import pytesseract
            pytesseract.get_tesseract_version()  # è¿™ä¼šæŠ›å‡ºå¼‚å¸¸å¦‚æœä¸å¯ç”¨

            # å°†é¡µé¢è½¬æ¢ä¸ºå›¾åƒ
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2xç¼©æ”¾æé«˜è´¨é‡
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))

            # OCRè¯†åˆ«
            text = pytesseract.image_to_string(img, lang='chi_sim+eng')
            return text
        except ImportError:
            print("pytesseract not available, OCR disabled")
            return ""
        except Exception as e:
            print(f"OCR failed: {e}")
            return ""


class QuestionParser:
    """é¢˜ç›®è§£æå™¨"""

    def __init__(self):
        # é¢˜ç›®ç±»å‹è¯†åˆ«æ¨¡å¼
        self.choice_pattern = re.compile(r'^(\d+)\.?\s*\(?([A-D])\)?', re.MULTILINE)
        self.blank_pattern = re.compile(r'(\d+)\.\s*\([^)]*____[^)]*\)', re.MULTILINE)
        self.solve_pattern = re.compile(r'(\d+)\.\s*\([^)]*åˆ†[^)]*\)', re.MULTILINE)

        # é€‰é¡¹è¯†åˆ«æ¨¡å¼
        self.option_pattern = re.compile(r'^([A-D])\.?\s*(.+)$', re.MULTILINE)

        # ç­”æ¡ˆè¯†åˆ«æ¨¡å¼
        self.answer_pattern = re.compile(r'ç­”æ¡ˆ[ï¼š:]\s*([A-D]|\d+|[^ã€‚\n]+)', re.MULTILINE)

        # åˆ†æ•°è¯†åˆ«æ¨¡å¼
        self.score_pattern = re.compile(r'\((\d+)åˆ†\)', re.MULTILINE)

    def parse_questions(self, pages_text: List[Tuple[int, str]], year: int) -> List[QuestionCandidate]:
        """è§£æé¢˜ç›®"""
        questions = []

        for page_num, text in pages_text:
            page_questions = self._parse_page_questions(text, year, page_num)
            questions.extend(page_questions)

        return questions

    def _parse_page_questions(self, text: str, year: int, page_num: int) -> List[QuestionCandidate]:
        """è§£æå•é¡µé¢˜ç›®"""
        questions = []

        # æ¸…ç†æ–‡æœ¬
        text = self._clean_text(text)

        # åˆ†å‰²é¢˜ç›®ï¼ˆé€šå¸¸ä»¥æ•°å­—å¼€å¤´ï¼‰
        question_blocks = self._split_questions(text)

        for i, block in enumerate(question_blocks):
            question = self._parse_single_question(block, year, i + 1, page_num)
            if question:
                questions.append(question)

        return questions

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = re.sub(r'\n+', '\n', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def _split_questions(self, text: str) -> List[str]:
        """åˆ†å‰²é¢˜ç›®å—"""
        # æŒ‰é¢˜å·åˆ†å‰²
        questions = []
        lines = text.split('\n')

        current_question = []
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°é¢˜ç›®çš„å¼€å§‹
            if re.match(r'^\d+\.', line.strip()):
                if current_question:
                    questions.append('\n'.join(current_question))
                current_question = [line]
            else:
                if current_question:
                    current_question.append(line)

        if current_question:
            questions.append('\n'.join(current_question))

        return questions

    def _parse_single_question(self, block: str, year: int, question_num: int, page_num: int) -> Optional[QuestionCandidate]:
        """è§£æå•ä¸ªé¢˜ç›®"""
        try:
            # ç¡®å®šé¢˜ç›®ç±»å‹
            question_type = self._determine_question_type(block)

            if not question_type:
                return None

            # ç”Ÿæˆé¢˜ç›®ID
            type_prefix = {'choice': 'c', 'blank': 'b', 'solve': 's'}[question_type]
            question_id = f"{year}-{type_prefix}-{question_num}"

            question = QuestionCandidate(
                id=question_id,
                type=question_type,
                content=block,
                page_num=page_num,
                confidence=0.5,  # åŸºç¡€ç½®ä¿¡åº¦
                parsing_notes="è‡ªåŠ¨è§£æï¼Œéœ€è¦äººå·¥å®¡æ ¸"
            )

            # æ ¹æ®ç±»å‹è§£æå…·ä½“å†…å®¹
            if question_type == 'choice':
                self._parse_choice_question(question, block)
            elif question_type == 'blank':
                self._parse_blank_question(question, block)
            elif question_type == 'solve':
                self._parse_solve_question(question, block)

            return question

        except Exception as e:
            print(f"Error parsing question {question_num}: {e}")
            return None

    def _determine_question_type(self, block: str) -> Optional[str]:
        """ç¡®å®šé¢˜ç›®ç±»å‹"""
        # æ£€æŸ¥æ˜¯å¦æœ‰é€‰é¡¹ï¼ˆé€‰æ‹©é¢˜ç‰¹å¾ï¼‰
        if self.option_pattern.search(block):
            return 'choice'

        # æ£€æŸ¥æ˜¯å¦æœ‰å¡«ç©ºç¬¦å·
        if '____' in block or 'ï¼ˆã€€ã€€ï¼‰' in block:
            return 'blank'

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æ•°ï¼ˆè§£ç­”é¢˜ç‰¹å¾ï¼‰
        if self.score_pattern.search(block):
            return 'solve'

        # é»˜è®¤å½“ä½œè§£ç­”é¢˜
        return 'solve'

    def _parse_choice_question(self, question: QuestionCandidate, block: str):
        """è§£æé€‰æ‹©é¢˜"""
        lines = block.split('\n')
        content_lines = []
        options = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯é€‰é¡¹
            option_match = self.option_pattern.match(line)
            if option_match:
                options.append(f"{option_match.group(1)}. {option_match.group(2)}")
            else:
                content_lines.append(line)

        question.content = '\n'.join(content_lines)
        question.options = options[:4]  # æœ€å¤š4ä¸ªé€‰é¡¹

        # å°è¯•æå–ç­”æ¡ˆ
        answer_match = self.answer_pattern.search(block)
        if answer_match:
            question.answer = answer_match.group(1).strip()

    def _parse_blank_question(self, question: QuestionCandidate, block: str):
        """è§£æå¡«ç©ºé¢˜"""
        # å¡«ç©ºé¢˜å†…å®¹å°±æ˜¯æ•´ä¸ªblock
        question.content = block

        # å°è¯•æå–ç­”æ¡ˆ
        answer_match = self.answer_pattern.search(block)
        if answer_match:
            answer = answer_match.group(1).strip()
            question.answer = answer
            question.accepted_answers = [answer]

    def _parse_solve_question(self, question: QuestionCandidate, block: str):
        """è§£æè§£ç­”é¢˜"""
        lines = block.split('\n')
        content_lines = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æå–åˆ†æ•°
            score_match = self.score_pattern.search(line)
            if score_match:
                question.score = int(score_match.group(1))
                # ç§»é™¤åˆ†æ•°ä¿¡æ¯
                line = self.score_pattern.sub('', line).strip()

            content_lines.append(line)

        question.content = '\n'.join(content_lines)

        # è§£ç­”é¢˜é€šå¸¸éœ€è¦å®Œæ•´çš„ç­”æ¡ˆå’Œè§£é¢˜æ­¥éª¤
        # è¿™é‡Œæš‚æ—¶åªè®¾ç½®åŸºæœ¬ç»“æ„


class DataExporter:
    """æ•°æ®å¯¼å‡ºå™¨"""

    def __init__(self, output_dir: str = "data", review_dir: str = "review", temp_dir: str = "tmp/exam_pages"):
        self.output_dir = Path(output_dir)
        self.review_dir = Path(review_dir)
        self.temp_dir = Path(temp_dir)

        # åˆ›å»ºç›®å½•
        self.output_dir.mkdir(exist_ok=True)
        self.review_dir.mkdir(exist_ok=True)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

    def export_candidate_json(self, questions: List[QuestionCandidate], year: int):
        """å¯¼å‡ºå€™é€‰JSONæ–‡ä»¶"""
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        question_dicts = []
        for q in questions:
            q_dict = {
                "id": q.id,
                "type": q.type,
                "content": q.content,
                "explanation": q.explanation,
                "knowledgePoints": q.knowledge_points or [],
                "page_num": q.page_num,
                "confidence": q.confidence,
                "parsing_notes": q.parsing_notes
            }

            if q.type == 'choice':
                q_dict.update({
                    "options": q.options or [],
                    "answer": q.answer or ""
                })
            elif q.type == 'blank':
                q_dict.update({
                    "answer": q.answer or "",
                    "acceptedAnswers": q.accepted_answers or []
                })
            elif q.type == 'solve':
                q_dict.update({
                    "score": q.score or 10,
                    "answer": q.answer or "",
                    "solution": q.solution or ""
                })

            question_dicts.append(q_dict)

        # å†™å…¥æ–‡ä»¶
        output_file = self.output_dir / f"real-exam-{year}.candidate.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(question_dicts, f, ensure_ascii=False, indent=2)

        print(f"Exported {len(question_dicts)} candidate questions to {output_file}")

    def export_review_csv(self, questions: List[QuestionCandidate], year: int):
        """å¯¼å‡ºå®¡æ ¸CSVæ–‡ä»¶"""
        csv_file = self.review_dir / f"{year}_mappings.csv"

        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'type', 'page_num', 'confidence', 'parsing_notes', 'content_preview'])

            for q in questions:
                content_preview = q.content[:100].replace('\n', ' ') + '...'
                writer.writerow([
                    q.id,
                    q.type,
                    q.page_num,
                    q.confidence,
                    q.parsing_notes,
                    content_preview
                ])

        print(f"Exported review CSV to {csv_file}")

    def export_page_texts(self, pages_text: List[Tuple[int, str]], year: int):
        """å¯¼å‡ºé¡µé¢æ–‡æœ¬æ–‡ä»¶"""
        year_dir = self.temp_dir / str(year)
        year_dir.mkdir(exist_ok=True)

        for page_num, text in pages_text:
            page_file = year_dir / f"{page_num:03d}.txt"
            with open(page_file, 'w', encoding='utf-8') as f:
                f.write(text)

        print(f"Exported {len(pages_text)} page text files to {year_dir}")


class ExamImporter:
    """å†å¹´çœŸé¢˜å¯¼å…¥å™¨"""

    def __init__(self):
        self.extractor = PDFTextExtractor()
        self.parser = QuestionParser()
        self.exporter = DataExporter()

    def import_year(self, pdf_path: str, year: int):
        """å¯¼å…¥ä¸€å¹´ä»½çš„çœŸé¢˜"""
        print(f"ğŸ”„ å¼€å§‹å¯¼å…¥ {year} å¹´çœŸé¢˜: {pdf_path}")

        # 1. æå–æ–‡æœ¬
        print("ğŸ“„ æå–PDFæ–‡æœ¬...")
        pages_text = self.extractor.extract_text(pdf_path)
        if not pages_text:
            print(f"âŒ æ— æ³•æå– {year} å¹´PDFæ–‡æœ¬")
            return False

        # 2. å¯¼å‡ºé¡µé¢æ–‡æœ¬
        self.exporter.export_page_texts(pages_text, year)

        # 3. è§£æé¢˜ç›®
        print("ğŸ” è§£æé¢˜ç›®...")
        questions = self.parser.parse_questions(pages_text, year)
        if not questions:
            print(f"âš ï¸ æœªæ‰¾åˆ° {year} å¹´çš„é¢˜ç›®")
            return False

        print(f"ğŸ“ å‘ç° {len(questions)} ä¸ªé¢˜ç›®å€™é€‰")

        # 4. å¯¼å‡ºå€™é€‰æ•°æ®
        self.exporter.export_candidate_json(questions, year)

        # 5. å¯¼å‡ºå®¡æ ¸æ–‡ä»¶
        self.exporter.export_review_csv(questions, year)

        print(f"âœ… {year} å¹´çœŸé¢˜å¯¼å…¥å®Œæˆ")
        return True

    def import_all_years(self, pdf_dir: str = "è€ƒç ”çœŸé¢˜"):
        """å¯¼å…¥æ‰€æœ‰å¹´ä»½çš„çœŸé¢˜"""
        pdf_dir = Path(pdf_dir)
        if not pdf_dir.exists():
            print(f"âŒ PDFç›®å½•ä¸å­˜åœ¨: {pdf_dir}")
            return

        # PDFæ–‡ä»¶ååˆ°å¹´ä»½çš„æ˜ å°„
        year_mapping = {
            "2026å¹´è€ƒç ”æ•°å­¦ä¸€çœŸé¢˜åŠå‚è€ƒç­”æ¡ˆ.pdf": 2026,
            "2025è€ƒç ”æ•°å­¦ï¼ˆä¸€ï¼‰çœŸé¢˜è¯•å·åŠè§£æè¯¦ç»†ç‰ˆ.pdf": 2025,
            "2024å¹´è€ƒç ”æ•°å­¦ä¸€çœŸé¢˜åŠç­”æ¡ˆ.pdf": 2024,
            "2023å¹´è€ƒç ”æ•°å­¦ä¸€è¯•é¢˜.pdf": 2023,
            "2023å¹´è€ƒç ”æ•°å­¦ä¸€å‚è€ƒç­”æ¡ˆåŠè§£æ.pdf": 2023,  # ç­”æ¡ˆæ–‡ä»¶
            "1987-2022æ•°ä¸€çœŸé¢˜åˆé›†.pdf": None,  # éœ€è¦ç‰¹æ®Šå¤„ç†
            "1987-2022æ•°ä¸€ç­”æ¡ˆ.pdf": None,  # éœ€è¦ç‰¹æ®Šå¤„ç†
        }

        success_count = 0
        for pdf_file in pdf_dir.glob("*.pdf"):
            year = year_mapping.get(pdf_file.name)
            if year is None:
                print(f"âš ï¸ è·³è¿‡æœªçŸ¥PDFæ–‡ä»¶: {pdf_file.name}")
                continue

            try:
                if self.import_year(str(pdf_file), year):
                    success_count += 1
            except Exception as e:
                print(f"âŒ å¯¼å…¥ {year} å¹´å¤±è´¥: {e}")

        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆ: {success_count} ä¸ªå¹´ä»½æˆåŠŸå¯¼å…¥")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è€ƒç ”æ•°å­¦å†å¹´çœŸé¢˜å¯¼å…¥å·¥å…·")
    print("=" * 50)

    importer = ExamImporter()

    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    import sys
    if len(sys.argv) > 1:
        # å¯¼å…¥æŒ‡å®šå¹´ä»½
        pdf_path = sys.argv[1]
        if len(sys.argv) > 2:
            year = int(sys.argv[2])
        else:
            # ä»æ–‡ä»¶åæ¨æ–­å¹´ä»½
            year_match = re.search(r'(\d{4})', pdf_path)
            year = int(year_match.group(1)) if year_match else 2024

        importer.import_year(pdf_path, year)
    else:
        # å¯¼å…¥æ‰€æœ‰å¹´ä»½
        importer.import_all_years()


if __name__ == "__main__":
    main()
